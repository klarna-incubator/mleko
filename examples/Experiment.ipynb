{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "%reload_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Imports\n",
        "Import the required classes and functions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "from mleko.dataset.convert import CSVToVaexConverter\n",
        "from mleko.dataset.feature_select import MissingRateFeatureSelector, VarianceFeatureSelector, CompositeFeatureSelector, PearsonCorrelationFeatureSelector\n",
        "from mleko.dataset.ingest import KaggleIngester\n",
        "from mleko.dataset.split import ExpressionSplitter, RandomSplitter\n",
        "from mleko.pipeline import Pipeline\n",
        "from mleko.pipeline.steps import ConvertStep, FeatureSelectStep, IngestStep, SplitStep"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Constants\n",
        "Define configuration variables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "OWNER_SLUG = 'mlg-ulb'\n",
        "DATASET_SLUG = 'creditcardfraud'\n",
        "DATASET_NAME = f'{OWNER_SLUG}/{DATASET_SLUG}'\n",
        "\n",
        "TARGET_FEATURE = \"Class\"\n",
        "TIME_FEATURE = \"Time\"\n",
        "META_FEATURES = [TIME_FEATURE, TARGET_FEATURE]\n",
        "RANDOM_STATE = 1337"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Pipeline Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2023-05-31 22:28:59] [\u001b[1;32mINFO\u001b[0m] Attempting to fetch Kaggle API credentials from environment variables 'KAGGLE_USERNAME' and 'KAGGLE_KEY'. \u001b[1m(kaggle_ingester.py:74)\u001b[0m\n",
            "[2023-05-31 22:28:59] [\u001b[1;33mWARNING\u001b[0m] Kaggle API credentials not found in environment variables, attempting to fetch from fallback path at ~/.kaggle/kaggle.json. \u001b[1m(kaggle_ingester.py:82)\u001b[0m\n",
            "[2023-05-31 22:28:59] [\u001b[1;32mINFO\u001b[0m] Kaggle credentials successfully fetched. \u001b[1m(kaggle_ingester.py:91)\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "kaggle_data_source = KaggleIngester(\n",
        "    output_directory=f\"data/{DATASET_NAME}/raw\", owner_slug=OWNER_SLUG, dataset_slug=DATASET_SLUG\n",
        ")\n",
        "csv_to_arrow_converter = CSVToVaexConverter(\n",
        "    output_directory=f\"data/{DATASET_NAME}/converted\", downcast_float=True, random_state=RANDOM_STATE\n",
        ")\n",
        "random_data_splitter = RandomSplitter(\n",
        "    cache_directory=f\"data/{DATASET_NAME}/split\",\n",
        "    data_split=(0.80, 0.20),\n",
        "    shuffle=True,\n",
        "    stratify=TARGET_FEATURE,\n",
        "    random_state=RANDOM_STATE,\n",
        ")\n",
        "expression_data_splitter = ExpressionSplitter(cache_directory=f\"data/{DATASET_NAME}/split\", expression=\"Time > 100\")\n",
        "composite_feature_selector = CompositeFeatureSelector(\n",
        "    cache_directory=f\"data/{DATASET_NAME}/feature_selection\",\n",
        "    feature_selectors=[\n",
        "        MissingRateFeatureSelector(\n",
        "            cache_directory=f\"data/{DATASET_NAME}/feature_selection\",\n",
        "            missing_rate_threshold=0.7,\n",
        "            ignore_features=META_FEATURES,\n",
        "        ),\n",
        "        VarianceFeatureSelector(\n",
        "            cache_directory=f\"data/{DATASET_NAME}/feature_selection\",\n",
        "            variance_threshold=0.00,\n",
        "            ignore_features=META_FEATURES\n",
        "        ),\n",
        "        PearsonCorrelationFeatureSelector(\n",
        "            cache_directory=f\"data/{DATASET_NAME}/feature_selection\",\n",
        "            correlation_threshold=0.7,\n",
        "            ignore_features=META_FEATURES\n",
        "        )\n",
        "    ],\n",
        ")\n",
        "\n",
        "\n",
        "pipeline = Pipeline(\n",
        "    steps=[\n",
        "        IngestStep(kaggle_data_source, outputs=[\"raw_csv\"]),\n",
        "        ConvertStep(csv_to_arrow_converter, inputs=[\"raw_csv\"], outputs=[\"df_clean\"]),\n",
        "        SplitStep(random_data_splitter, inputs=[\"df_clean\"], outputs=[\"df_train_validate\", \"df_test\"]),\n",
        "        SplitStep(expression_data_splitter, inputs=[\"df_train_validate\"], outputs=[\"df_train\", \"df_validate\"]),\n",
        "        FeatureSelectStep(\n",
        "            composite_feature_selector,\n",
        "            inputs=[\"df_train\"],\n",
        "            outputs=[\"df_train_features_selected\"],\n",
        "        ),\n",
        "    ]\n",
        ")\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Run Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2023-05-31 22:29:06] [\u001b[1;32mINFO\u001b[0m] No data container provided. Creating an empty one. \u001b[1m(pipeline.py:77)\u001b[0m\n",
            "[2023-05-31 22:29:06] [\u001b[1;32mINFO\u001b[0m] Executing step 1: IngestStep. \u001b[1m(pipeline.py:81)\u001b[0m\n",
            "[2023-05-31 22:29:06] [\u001b[1;32mINFO\u001b[0m] \u001b[33mForce Cache Refresh\u001b[0m: Downloading mlg-ulb/creditcardfraud/* to data/mlg-ulb/creditcardfraud/raw from Kaggle. \u001b[1m(kaggle_ingester.py:287)\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading files from Kaggle: 100%|██████████| 1/1 [00:04<00:00,  4.88s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2023-05-31 22:29:11] [\u001b[1;32mINFO\u001b[0m] Finished downloading 1 files from Kaggle. \u001b[1m(kaggle_ingester.py:303)\u001b[0m\n",
            "[2023-05-31 22:29:11] [\u001b[1;32mINFO\u001b[0m] Finished step 1 execution. \u001b[1m(pipeline.py:83)\u001b[0m\n",
            "[2023-05-31 22:29:11] [\u001b[1;32mINFO\u001b[0m] Executing step 2: ConvertStep. \u001b[1m(pipeline.py:81)\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2023-05-31 22:29:12] [\u001b[1;32mINFO\u001b[0m] \u001b[33mForce Cache Refresh\u001b[0m (LRUCache) CSVToVaexConverter.convert: Executing method. \u001b[1m(cache_mixin.py:133)\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Converting CSV files: 100%|██████████| 1/1 [00:04<00:00,  4.08s/it]\n",
            "Writing DataFrame to Arrow file: 100%|██████████| 100/100 [00:00<00:00, 116.63it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2023-05-31 22:29:17] [\u001b[1;32mINFO\u001b[0m] Finished step 2 execution. \u001b[1m(pipeline.py:83)\u001b[0m\n",
            "[2023-05-31 22:29:17] [\u001b[1;32mINFO\u001b[0m] Executing step 3: SplitStep. \u001b[1m(pipeline.py:81)\u001b[0m\n",
            "[2023-05-31 22:29:17] [\u001b[1;32mINFO\u001b[0m] \u001b[33mForce Cache Refresh\u001b[0m (LRUCache) RandomSplitter.split: Executing method. \u001b[1m(cache_mixin.py:133)\u001b[0m\n",
            "[2023-05-31 22:29:17] [\u001b[1;32mINFO\u001b[0m] Shuffling data before splitting. \u001b[1m(random_splitter.py:122)\u001b[0m\n",
            "[2023-05-31 22:29:17] [\u001b[1;32mINFO\u001b[0m] Splitting data with stratification on column 'Class'. \u001b[1m(random_splitter.py:126)\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2023-05-31 22:29:17] [\u001b[1;32mINFO\u001b[0m] Split dataframe into two dataframes with shapes (227845, 32) and (56962, 32). \u001b[1m(random_splitter.py:138)\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Writing DataFrame to Arrow file: 100%|██████████| 100/100 [00:00<00:00, 373.38it/s]\n",
            "Writing DataFrame to Arrow file: 100%|██████████| 100/100 [00:00<00:00, 484.15it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2023-05-31 22:29:18] [\u001b[1;32mINFO\u001b[0m] Finished step 3 execution. \u001b[1m(pipeline.py:83)\u001b[0m\n",
            "[2023-05-31 22:29:18] [\u001b[1;32mINFO\u001b[0m] Executing step 4: SplitStep. \u001b[1m(pipeline.py:81)\u001b[0m\n",
            "[2023-05-31 22:29:18] [\u001b[1;32mINFO\u001b[0m] \u001b[33mForce Cache Refresh\u001b[0m (LRUCache) ExpressionSplitter.split: Executing method. \u001b[1m(cache_mixin.py:133)\u001b[0m\n",
            "[2023-05-31 22:29:18] [\u001b[1;32mINFO\u001b[0m] Splitting dataframe based on expression 'Time > 100'. \u001b[1m(expression_splitter.py:92)\u001b[0m\n",
            "[2023-05-31 22:29:18] [\u001b[1;32mINFO\u001b[0m] Split dataframe into two dataframes with shapes (227718, 31) and (127, 31). \u001b[1m(expression_splitter.py:95)\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Writing DataFrame to Arrow file: 100%|██████████| 100/100 [00:00<00:00, 396.73it/s]\n",
            "Writing DataFrame to Arrow file: 100%|██████████| 100/100 [00:00<00:00, 2485.15it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2023-05-31 22:29:18] [\u001b[1;32mINFO\u001b[0m] Finished step 4 execution. \u001b[1m(pipeline.py:83)\u001b[0m\n",
            "[2023-05-31 22:29:18] [\u001b[1;32mINFO\u001b[0m] Executing step 5: FeatureSelectStep. \u001b[1m(pipeline.py:81)\u001b[0m\n",
            "[2023-05-31 22:29:18] [\u001b[1;32mINFO\u001b[0m] \u001b[33mForce Cache Refresh\u001b[0m (LRUCache) CompositeFeatureSelector.select_features: Executing method. \u001b[1m(cache_mixin.py:133)\u001b[0m\n",
            "[2023-05-31 22:29:18] [\u001b[1;32mINFO\u001b[0m] Selecting features from the following set: ['Amount', 'V1', 'V10', 'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V2', 'V20', 'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9']. \u001b[1m(missing_rate_feature_selector.py:100)\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Calculating missing rates for features: 100%|██████████| 29/29 [00:00<00:00, 49.82it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2023-05-31 22:29:19] [\u001b[1;32mINFO\u001b[0m] Dropping features with missing rate >= 0.7: set(). \u001b[1m(missing_rate_feature_selector.py:108)\u001b[0m\n",
            "[2023-05-31 22:29:19] [\u001b[1;32mINFO\u001b[0m] Selecting features from the following set: ['Amount', 'V1', 'V10', 'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V2', 'V20', 'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9']. \u001b[1m(variance_feature_selector.py:104)\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Calculating variance for features: 100%|██████████| 29/29 [00:01<00:00, 27.10it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2023-05-31 22:29:20] [\u001b[1;32mINFO\u001b[0m] Dropping features with normalized variance <= 0.0: set(). \u001b[1m(variance_feature_selector.py:114)\u001b[0m\n",
            "[2023-05-31 22:29:20] [\u001b[1;32mINFO\u001b[0m] Selecting features from the following set: ['Amount', 'V1', 'V10', 'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V2', 'V20', 'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9']. \u001b[1m(pearson_correlation_feature_selector.py:44)\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2023-05-31 22:29:20] [\u001b[1;32mINFO\u001b[0m] Dropping features with correlation >= 0.7: set(). \u001b[1m(pearson_correlation_feature_selector.py:90)\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Writing DataFrame to Arrow file: 100%|██████████| 100/100 [00:00<00:00, 865.50it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2023-05-31 22:29:20] [\u001b[1;32mINFO\u001b[0m] Finished step 5 execution. \u001b[1m(pipeline.py:83)\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "data_container =  pipeline.run(force_recompute=True).data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2023-05-31 22:52:06] [\u001b[1;32mINFO\u001b[0m] \u001b[32mCache Hit\u001b[0m (LRUCache) PearsonCorrelationFeatureSelector.select_features: Using cached output. \u001b[1m(cache_mixin.py:124)\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['a', 'c']"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import vaex\n",
        "from mleko.dataset.feature_select import PearsonCorrelationFeatureSelector\n",
        "from mleko.utils.vaex_helpers import get_column\n",
        "df = vaex.from_arrays(\n",
        "     a=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
        "     b=[1, 2, 3, 4, 5, 6, 7, 8, 9, 9],\n",
        "     c=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
        " )\n",
        "feature_selector = PearsonCorrelationFeatureSelector(\n",
        "    cache_directory=\".\",\n",
        "    correlation_threshold=0.75,\n",
        ")\n",
        "selected_features = feature_selector.select_features(df)\n",
        "selected_features.get_column_names()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.16"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "9611670ec755352ff717d7a41a0ab877947349e5431e69ecf0edefdfa5d80e71"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
