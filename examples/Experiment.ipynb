{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "%reload_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Imports\n",
        "Import the required classes and functions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "from mleko.dataset.ingest import KaggleIngester\n",
        "from mleko.dataset.convert import CSVToVaexConverter\n",
        "from mleko.dataset.split import RandomSplitter, ExpressionSplitter\n",
        "from mleko.pipeline import Pipeline\n",
        "from mleko.pipeline.steps import IngestStep, ConvertStep, SplitStep, FeatureSelectStep\n",
        "from mleko.dataset.feature_select import MissingRateFeatureSelector, StandardDeviationFeatureSelector"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Constants\n",
        "Define configuration variables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "OWNER_SLUG = 'mlg-ulb'\n",
        "DATASET_SLUG = 'creditcardfraud'\n",
        "DATASET_NAME = f'{OWNER_SLUG}/{DATASET_SLUG}'\n",
        "\n",
        "TARGET_FEATURE = \"Class\"\n",
        "TIME_FEATURE = \"Time\"\n",
        "META_FEATURES = [TIME_FEATURE, TARGET_FEATURE]\n",
        "RANDOM_STATE = 1337"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Pipeline Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2023-05-25 22:39:45] [\u001b[1;32mINFO\u001b[0m] Attempting to fetch Kaggle API credentials from environment variables 'KAGGLE_USERNAME' and 'KAGGLE_KEY'. \u001b[1m(kaggle_ingester.py:77)\u001b[0m\n",
            "[2023-05-25 22:39:45] [\u001b[1;33mWARNING\u001b[0m] Kaggle API credentials not found in environment variables, attempting to fetch from fallback path at ~/.kaggle/kaggle.json. \u001b[1m(kaggle_ingester.py:85)\u001b[0m\n",
            "[2023-05-25 22:39:45] [\u001b[1;32mINFO\u001b[0m] Kaggle credentials successfully fetched. \u001b[1m(kaggle_ingester.py:94)\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "kaggle_data_source = KaggleIngester(f\"data/{DATASET_NAME}/raw\", owner_slug=OWNER_SLUG, dataset_slug=DATASET_SLUG)\n",
        "csv_to_arrow_converter = CSVToVaexConverter(\n",
        "    output_directory=f\"data/{DATASET_NAME}/converted\", downcast_float=True, random_state=RANDOM_STATE\n",
        ")\n",
        "random_data_splitter = RandomSplitter(\n",
        "    output_directory=f\"data/{DATASET_NAME}/split\",\n",
        "    data_split=(0.80, 0.20),\n",
        "    shuffle=True,\n",
        "    stratify=TARGET_FEATURE,\n",
        "    random_state=RANDOM_STATE,\n",
        ")\n",
        "expression_data_splitter = ExpressionSplitter(output_directory=f\"data/{DATASET_NAME}/split\", expression=\"Time > 100\")\n",
        "missing_rate_feature_selector = MissingRateFeatureSelector(\n",
        "    output_directory=f\"data/{DATASET_NAME}/feature_selection\", missing_rate_threshold=0.3, ignore_features=META_FEATURES\n",
        ")\n",
        "standard_deviation_feature_selector = StandardDeviationFeatureSelector(\n",
        "    output_directory=f\"data/{DATASET_NAME}/feature_selection\",\n",
        "    standard_deviation_threshold=0.00,\n",
        "    ignore_features=META_FEATURES,\n",
        ")\n",
        "\n",
        "\n",
        "pipeline = Pipeline(\n",
        "    steps=[\n",
        "        IngestStep(kaggle_data_source, outputs=[\"raw_csv\"]),\n",
        "        ConvertStep(csv_to_arrow_converter, inputs=[\"raw_csv\"], outputs=[\"df_clean\"]),\n",
        "        SplitStep(random_data_splitter, inputs=[\"df_clean\"], outputs=[\"df_train_validate\", \"df_test\"]),\n",
        "        SplitStep(expression_data_splitter, inputs=[\"df_train_validate\"], outputs=[\"df_train\", \"df_validate\"]),\n",
        "        FeatureSelectStep(missing_rate_feature_selector, inputs=[\"df_train\"], outputs=[\"df_train_missing_rate\"]),\n",
        "        FeatureSelectStep(\n",
        "            standard_deviation_feature_selector,\n",
        "            inputs=[\"df_train_missing_rate\"],\n",
        "            outputs=[\"df_train_standard_deviation\"],\n",
        "        ),\n",
        "    ]\n",
        ")\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Run Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2023-05-25 22:39:58] [\u001b[1;32mINFO\u001b[0m] No data container provided. Creating an empty one. \u001b[1m(pipeline.py:77)\u001b[0m\n",
            "[2023-05-25 22:39:58] [\u001b[1;32mINFO\u001b[0m] Executing step 1: IngestStep. \u001b[1m(pipeline.py:81)\u001b[0m\n",
            "[2023-05-25 22:39:59] [\u001b[1;32mINFO\u001b[0m] \u001b[32mCache Hit\u001b[0m: Local dataset is up to date with Kaggle, skipping download. \u001b[1m(kaggle_ingester.py:283)\u001b[0m\n",
            "[2023-05-25 22:39:59] [\u001b[1;32mINFO\u001b[0m] Finished step 1 execution. \u001b[1m(pipeline.py:83)\u001b[0m\n",
            "[2023-05-25 22:39:59] [\u001b[1;32mINFO\u001b[0m] Executing step 2: ConvertStep. \u001b[1m(pipeline.py:81)\u001b[0m\n",
            "[2023-05-25 22:39:59] [\u001b[1;32mINFO\u001b[0m] \u001b[32mCache Hit\u001b[0m (LRUCache) CSVToVaexConverter.convert: Using cached output. \u001b[1m(cache_mixin.py:126)\u001b[0m\n",
            "[2023-05-25 22:39:59] [\u001b[1;32mINFO\u001b[0m] Finished step 2 execution. \u001b[1m(pipeline.py:83)\u001b[0m\n",
            "[2023-05-25 22:39:59] [\u001b[1;32mINFO\u001b[0m] Executing step 3: SplitStep. \u001b[1m(pipeline.py:81)\u001b[0m\n",
            "[2023-05-25 22:39:59] [\u001b[1;32mINFO\u001b[0m] \u001b[32mCache Hit\u001b[0m (LRUCache) RandomSplitter.split: Using cached output. \u001b[1m(cache_mixin.py:126)\u001b[0m\n",
            "[2023-05-25 22:39:59] [\u001b[1;32mINFO\u001b[0m] Finished step 3 execution. \u001b[1m(pipeline.py:83)\u001b[0m\n",
            "[2023-05-25 22:39:59] [\u001b[1;32mINFO\u001b[0m] Executing step 4: SplitStep. \u001b[1m(pipeline.py:81)\u001b[0m\n",
            "[2023-05-25 22:39:59] [\u001b[1;32mINFO\u001b[0m] \u001b[32mCache Hit\u001b[0m (LRUCache) ExpressionSplitter.split: Using cached output. \u001b[1m(cache_mixin.py:126)\u001b[0m\n",
            "[2023-05-25 22:39:59] [\u001b[1;32mINFO\u001b[0m] Finished step 4 execution. \u001b[1m(pipeline.py:83)\u001b[0m\n",
            "[2023-05-25 22:39:59] [\u001b[1;32mINFO\u001b[0m] Executing step 5: FeatureSelectStep. \u001b[1m(pipeline.py:81)\u001b[0m\n",
            "[2023-05-25 22:39:59] [\u001b[1;32mINFO\u001b[0m] \u001b[32mCache Hit\u001b[0m (LRUCache) MissingRateFeatureSelector.select_features: Using cached output. \u001b[1m(cache_mixin.py:126)\u001b[0m\n",
            "[2023-05-25 22:39:59] [\u001b[1;32mINFO\u001b[0m] Finished step 5 execution. \u001b[1m(pipeline.py:83)\u001b[0m\n",
            "[2023-05-25 22:39:59] [\u001b[1;32mINFO\u001b[0m] Executing step 6: FeatureSelectStep. \u001b[1m(pipeline.py:81)\u001b[0m\n",
            "[2023-05-25 22:39:59] [\u001b[1;32mINFO\u001b[0m] \u001b[32mCache Hit\u001b[0m (LRUCache) StandardDeviationFeatureSelector.select_features: Using cached output. \u001b[1m(cache_mixin.py:126)\u001b[0m\n",
            "[2023-05-25 22:39:59] [\u001b[1;32mINFO\u001b[0m] Finished step 6 execution. \u001b[1m(pipeline.py:83)\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "data_container =  pipeline.run().data"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.16"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "9611670ec755352ff717d7a41a0ab877947349e5431e69ecf0edefdfa5d80e71"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
