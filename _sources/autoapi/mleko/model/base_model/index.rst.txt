:py:mod:`mleko.model.base_model`
================================

.. py:module:: mleko.model.base_model

.. autoapi-nested-parse::

   Module for the base model class.



Module Contents
---------------

Classes
~~~~~~~

.. autoapisummary::

   mleko.model.base_model.BaseModel




Attributes
~~~~~~~~~~

.. autoapisummary::

   mleko.model.base_model.logger
   mleko.model.base_model.HyperparametersType


.. py:data:: logger

   The logger for the module.

.. py:data:: HyperparametersType

   

.. py:class:: BaseModel(features: list[str] | tuple[str, Ellipsis] | None, ignore_features: list[str] | tuple[str, Ellipsis] | None, verbosity: int, memoized_dataset_cache_size: int | None, cache_directory: str | pathlib.Path, cache_size: int)

   Bases: :py:obj:`mleko.cache.lru_cache_mixin.LRUCacheMixin`, :py:obj:`abc.ABC`

   Abstract class for models.

   The model fitting and transformation process is implemented in the `fit`, `transform`, and `fit_transform` methods,
   similar to the scikit-learn API. The `fit` method fits the model to the specified DataFrame, the `transform`
   method transforms the specified features in the DataFrame, and the `fit_transform` method fits the model to the
   specified DataFrame and transforms the specified features in the DataFrame.

   Initializes the model and ensures the destination directory exists.

   .. note::

      The `features` and `ignore_features` arguments are mutually exclusive. If both are specified, a
      `ValueError` is raised.

   .. warning::

      The `memoized_dataset_cache_size` parameter is experimental and should be used with caution. It refers to
      the number of datasets to keep in memory for speeding up repeated training. This can be useful when
      hyperparameter tuning or cross-validation is performed, as the dataset does not need to be loaded from disk
      every time. However, this can lead to memory issues if the dataset is too large. Specify 0 to disable the
      cache. When finished with the fitting and transforming, please call the `_clear_dataset_cache` method to
      clear the cache and free up memory.

   :param features: List of feature names to be used by the model. If None, the default is all features
                    applicable to the model.
   :param ignore_features: List of feature names to be ignored by the model. If None, the default is to
                           ignore no features.
   :param verbosity: The verbosity level of the logger, should be passed to the underlying model.
   :param memoized_dataset_cache_size: The number of datasets to keep in memory for speeding up repeated training.
                                       When finished with the fitting and transforming, please call the `_clear_dataset_cache` method to clear
                                       the cache and free up memory. Specify 0 to disable the cache.
   :param cache_directory: Directory where the cache will be stored locally.
   :param cache_size: The maximum number of entries to keep in the cache.

   :raises ValueError: If both `features` and `ignore_features` are specified.

   .. py:method:: fit(data_schema: mleko.dataset.data_schema.DataSchema, train_dataframe: vaex.DataFrame, validation_dataframe: vaex.DataFrame | None = None, hyperparameters: HyperparametersType | None = None, cache_group: str | None = None, force_recompute: bool = False, disable_cache: bool = False) -> tuple[Any, dict[str, dict[str, list[Any]]]]

      Fits the model to the specified DataFrame, using the specified hyperparameters.

      The validation DataFrame is used to validate the model during fitting.

      :param data_schema: Data schema for the DataFrame.
      :param train_dataframe: DataFrame to fit the model on.
      :param validation_dataframe: DataFrame to be used for validation.
      :param hyperparameters: Hyperparameters to be used for fitting. If any hyperparameters are specified, they will
                              be merged with the default hyperparameters specified during the model initialization.
      :param cache_group: The cache group to use for caching.
      :param force_recompute: Whether to force recompute the result.
      :param disable_cache: If set to True, disables the cache.

      :returns: Fitted model and the metrics dictionary. The metrics dictionary is a dictionary of dictionaries. The outer
                dictionary is keyed by the dataset name, and the inner dictionary is keyed by the metric name. The value
                of the inner dictionary is a list of metric values for each iteration of the model.
                >>> metrics = {
                ...     "train": {
                ...         "accuracy": [0.90, 0.91, 0.92],
                ...         "f1": [0.80, 0.81, 0.82],
                ...     },
                ...     "validation": {
                ...         "accuracy": [0.80, 0.81, 0.82],
                ...         "f1": [0.70, 0.71, 0.72],
                ...     },
                ... }


   .. py:method:: transform(data_schema: mleko.dataset.data_schema.DataSchema, dataframe: vaex.DataFrame, cache_group: str | None = None, force_recompute: bool = False, disable_cache: bool = False) -> vaex.DataFrame

      Transforms the specified DataFrame using the fitted model.

      :param data_schema: Data schema for the DataFrame.
      :param dataframe: DataFrame to be transformed.
      :param cache_group: The cache group to use for caching.
      :param force_recompute: Whether to force recompute the result.
      :param disable_cache: If set to True, disables the cache.

      :raises RuntimeError: If the model has not been fitted.

      :returns: Transformed DataFrame.


   .. py:method:: fit_transform(data_schema: mleko.dataset.data_schema.DataSchema, train_dataframe: vaex.DataFrame, validation_dataframe: vaex.DataFrame | None = None, hyperparameters: HyperparametersType | None = None, cache_group: str | None = None, force_recompute: bool = False, disable_cache: bool = False) -> tuple[Any, dict[str, dict[str, list[Any]]], vaex.DataFrame, vaex.DataFrame | None]

      Fits the model to the specified DataFrame and transforms the train and validation DataFrames.

      The validation DataFrame is used to validate the model during fitting.

      :param data_schema: Data schema for the DataFrame.
      :param train_dataframe: DataFrame to fit the model on.
      :param validation_dataframe: DataFrame to be used for validation.
      :param hyperparameters: Hyperparameters to be used for fitting.
      :param cache_group: The cache group to use for caching.
      :param force_recompute: Whether to force recompute the result.
      :param disable_cache: If set to True, disables the cache.

      :returns: Tuple of fitted model, the metrics dictionary, transformed train DataFrame,
                and transformed validation DataFrame. The metrics dictionary is a dictionary of dictionaries.
                The outer dictionary is keyed by the dataset name, and the inner dictionary is keyed by the
                metric name. The value of the inner dictionary is a list of metric values for each
                iteration of the model.
                >>> metrics = {
                ...     "train": {
                ...         "accuracy": [0.90, 0.91, 0.92],
                ...         "f1": [0.80, 0.81, 0.82],
                ...     },
                ...     "validation": {
                ...         "accuracy": [0.80, 0.81, 0.82],
                ...         "f1": [0.70, 0.71, 0.72],
                ...     },
                ... }


   .. py:method:: clear_load_dataset_cache() -> None

      Clears the cache for the `_memoized_load_dataset` method.


   .. py:method:: _fit_transform(data_schema: mleko.dataset.data_schema.DataSchema, train_dataframe: vaex.DataFrame, validation_dataframe: vaex.DataFrame | None = None, hyperparameters: HyperparametersType | None = None) -> tuple[Any, dict[str, dict[str, list[Any]]], vaex.DataFrame, vaex.DataFrame | None]

      Fits the model to the specified DataFrame and transforms the train and validation DataFrames.

      :param data_schema: Data schema for the DataFrame.
      :param train_dataframe: DataFrame to fit the model on.
      :param validation_dataframe: DataFrame to be used for validation.
      :param hyperparameters: Hyperparameters to be used for fitting.

      :returns: Tuple of fitted model, the metrics dictionary, transformed train DataFrame, and
                transformed validation DataFrame.


   .. py:method:: _assign_model(model: Any) -> None

      Assigns the specified model to the model attribute.

      Can be overridden by subclasses to assign the model using a different method.

      :param model: Model to be assigned.


   .. py:method:: _feature_set(data_schema: mleko.dataset.data_schema.DataSchema) -> list[str]

      Returns the list of features to be used as input by the model.

      It is the default set of features minus the features to be ignored if the `features` argument is None, or the
      list of names in the `features` argument if it is not None.

      :param data_schema: Data schema for the DataFrame.

      :returns: Sorted list of feature names to be used by the model.


   .. py:method:: _load_dataset(data_schema: mleko.dataset.data_schema.DataSchema, dataframe: vaex.DataFrame, additional_features: list[str] | None = None) -> pandas.DataFrame

      Load the dataset into memory.

      .. warning:: This method should be used with caution, as it loads the entire dataset into memory as a pandas DataFrame.

      :param data_schema: The data schema of the dataframe.
      :param dataframe: The dataframe to load.
      :param additional_features: Additional features to load, such as the target feature.

      :returns: A pandas DataFrame with the loaded data.


   .. py:method:: _memoized_load_dataset(data_schema: mleko.dataset.data_schema.DataSchema, dataframe: mleko.utils.vaex_helpers.HashableVaexDataFrame, additional_features: tuple[str, Ellipsis] | None = None, name: str | None = None) -> pandas.DataFrame

      Load the dataset into memory and memoize the result.

      .. warning::

         This method should be used with caution, as it loads the entire dataset into memory as a pandas DataFrame.
         The returned DataFrame will be memoized using the `functools.lru_cache` to avoid reloading the
         dataset multiple times. The cache size is set to the `memoized_dataset_cache_size` attribute.

      :param data_schema: The data schema of the dataframe.
      :param dataframe: The dataframe to load, wrapped in a `HashableVaexDataFrame` object.
      :param additional_features: Additional features to load, such as the target feature.
      :param name: Name of the dataset to be used in the log message.

      :returns: A pandas DataFrame with the loaded data.


   .. py:method:: _fit(data_schema: mleko.dataset.data_schema.DataSchema, train_dataframe: vaex.DataFrame, validation_dataframe: vaex.DataFrame | None = None, hyperparameters: HyperparametersType | None = None) -> tuple[Any, dict[str, dict[str, list[Any]]]]
      :abstractmethod:

      Fits the model to the specified DataFrame.

      :param data_schema: Data schema for the DataFrame.
      :param train_dataframe: DataFrame to be fitted.
      :param validation_dataframe: DataFrame to be used for validation.
      :param hyperparameters: Hyperparameters to be used for fitting.

      :raises NotImplementedError: Must be implemented by subclasses.


   .. py:method:: _transform(data_schema: mleko.dataset.data_schema.DataSchema, dataframe: vaex.DataFrame) -> vaex.DataFrame
      :abstractmethod:

      Transforms the specified DataFrame using the fitted model.

      :param data_schema: Data schema for the DataFrame.
      :param dataframe: DataFrame to be transformed.

      :raises NotImplementedError: Must be implemented by subclasses.


   .. py:method:: _fingerprint() -> Hashable
      :abstractmethod:

      Returns a hashable object that uniquely identifies the model.

      The base implementation fingerprints the class name and the important attributes of the model.

      .. note::

         Subclasses should call the parent method and include the result in the hashable object along with any
         other parameters that uniquely identify the model. All attributes that are used in the
         model that affect the result of the fitting and transforming should be included in the hashable object.

      :returns: Hashable object that uniquely identifies the model.


   .. py:method:: _default_features(data_schema: mleko.dataset.data_schema.DataSchema) -> tuple[str, Ellipsis]
      :abstractmethod:

      Returns the default set of features to be used by the model.

      :param data_schema: Data schema for the DataFrame.

      :raises NotImplementedError: Must be implemented in the child class that inherits from `BaseModel`.


   .. py:method:: _load_cache_from_disk() -> None

      Loads the cache entries from the cache directory and initializes the LRU cache.

      Cache entries are ordered by their modification time, and the cache is trimmed if needed.


   .. py:method:: _load_from_cache(cache_key: str, cache_handlers: mleko.cache.handlers.CacheHandler | list[mleko.cache.handlers.CacheHandler]) -> Any | None

      Loads data from the cache based on the provided cache key and updates the LRU cache.

      :param cache_key: A string representing the cache key.
      :param cache_handlers: A CacheHandler instance or a list of CacheHandler instances. If a single CacheHandler
                             instance is provided, it will be used for all cache files. If a list of CacheHandler instances is
                             provided, each CacheHandler instance will be used for each cache file.

      :returns: The cached data if it exists, or None if there is no data for the given cache key.


   .. py:method:: _save_to_cache(cache_key: str, output: Any | Sequence[Any], cache_handlers: mleko.cache.handlers.CacheHandler | list[mleko.cache.handlers.CacheHandler]) -> None

      Saves the given data to the cache using the provided cache key, updating the LRU cache accordingly.

      If the cache reaches its maximum size, the least recently used entry will be evicted.

      :param cache_key: A string representing the cache key.
      :param output: The data to be saved to the cache.
      :param cache_handlers: A CacheHandler instance or a list of CacheHandler instances. If a single CacheHandler
                             instance is provided, it will be used for all cache files. If a list of CacheHandler instances is
                             provided, each CacheHandler instance will be used for each cache file.


   .. py:method:: _evict_least_recently_used_if_full(group_identifier: str) -> None

      Evicts the least recently used cache entry if the cache is full.

      :param group_identifier: The group identifier for the cache entries.


   .. py:method:: _cached_execute(lambda_func: Callable[[], Any], cache_key_inputs: list[Hashable | tuple[Any, mleko.cache.fingerprinters.base_fingerprinter.BaseFingerprinter]], cache_group: str | None = None, force_recompute: bool = False, cache_handlers: mleko.cache.handlers.CacheHandler | list[mleko.cache.handlers.CacheHandler] | None = None, disable_cache: bool = False) -> Any

      Executes the given function, caching the results based on the provided cache keys and fingerprints.

      .. warning::

         The cache group is used to group related cache keys together to prevent collisions between cache keys
         originating from the same method. For example, if a method is called during the training and testing
         phases of a machine learning pipeline, the cache keys for the training and testing phases should be
         using different cache groups to prevent collisions between the cache keys for the two phases. Otherwise,
         the later cache keys might overwrite the earlier cache entries.

      :param lambda_func: A lambda function to execute.
      :param cache_key_inputs: A list of cache keys that can be a mix of hashable values and tuples containing
                               a value and a BaseFingerprinter instance for generating fingerprints.
      :param cache_group: A string representing the cache group, used to group related cache keys together when methods
                          are called independently.
      :param force_recompute: A boolean indicating whether to force recompute the result and update the cache, even if a
                              cached result is available.
      :param cache_handlers: A CacheHandler instance or a list of CacheHandler instances. If None, the cache files will
                             be read using pickle. If a single CacheHandler instance is provided, it will be used for all cache
                             files. If a list of CacheHandler instances is provided, each CacheHandler instance will be used for
                             each cache file.
      :param disable_cache: Overrides the class-level `disable_cache` attribute. If set to True, disables the cache.

      :returns: A tuple containing a boolean indicating whether the cached result was used, and the result of executing the
                given function. If a cached result is available and `force_recompute` is False, the cached result will be
                returned instead of recomputing the result.


   .. py:method:: _compute_cache_key(cache_key_inputs: list[Hashable | tuple[Any, mleko.cache.fingerprinters.base_fingerprinter.BaseFingerprinter]], cache_group: str | None = None, frame_depth: int = 3) -> str

      Computes the cache key based on the provided cache keys and the calling function's fully qualified name.

      :param cache_key_inputs: A list of cache keys that can be a mix of hashable values and tuples containing a
                               value and a BaseFingerprinter instance for generating fingerprints.
      :param cache_group: A string representing the cache group.
      :param frame_depth: The depth of the frame to inspect. The default value is 2, which is the frame of the calling
                          function or method. For each nested function or method, the frame depth should be increased by 1.

      :raises ValueError: If the computed cache key is too long.

      :returns: A string representing the computed cache key, which is the MD5 hash of the fully qualified name of the
                calling function or method, along with the fingerprints of the provided cache keys.


   .. py:method:: _get_handler(cache_handlers: mleko.cache.handlers.CacheHandler | list[mleko.cache.handlers.CacheHandler], index: int = 0) -> mleko.cache.handlers.CacheHandler

      Gets the cache handler at the given index.

      :param cache_handlers: A CacheHandler instance or a list of CacheHandler instances.
      :param index: The index of the cache handler to get.

      :returns: Handler at the given index. If a single CacheHandler instance is provided, it will be returned.


   .. py:method:: _write_to_cache_file(cache_key: str, output_item: Any, index: int, cache_handlers: mleko.cache.handlers.CacheHandler | list[mleko.cache.handlers.CacheHandler], is_sequence_output: bool) -> None

      Writes the given data to the cache file using the provided cache key.

      If the output is None and the cache handler cannot handle None, the output will be saved using the pickle
      cache handler. Otherwise, the output will be saved to a cache file using the provided cache handler.

      :param cache_key: A string representing the cache key.
      :param output_item: The data to be saved to the cache.
      :param index: The index of the cache handler to use.
      :param cache_handlers: A CacheHandler instance or a list of CacheHandler instances.
      :param is_sequence_output: Whether the output is a sequence or not. If True, the cache file will be saved with the
                                 index appended to the cache key.


   .. py:method:: _find_cache_type_name(cls: type) -> str | None

      Recursively searches the class hierarchy for the name of the class that inherits from `CacheMixin`.

      :param cls: The class to search.

      :returns: The name of the class that inherits from `CacheMixin`, or None if no such class exists.



